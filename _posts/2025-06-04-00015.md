---

title: "[MIT6.034] 15.언어 학습과 제약 기반 학습: Sussman-Yip 시스템"
date: 2025-06-05 03:30:00 +0900
categories: [AI, AI-Lecture]
tags: [MIT-6.034, Language, Phonology, Constraint-Propagation, Sparse-Space]
math: true
---

**🗣️ MIT AI 강의 15 - 언어 규칙 학습과 제약 기반 시스템: Sussman-Yip 구조**

---

## 🧭 도입: 기존 학습 시스템 회고

* 기초: 최근접 이웃(Nearest Neighbor), 식별 트리(Identification Tree)
* 생물학적 모방: 신경망, 유전 알고리즘 → **피스타린(pistareen: 가치 없는 동전)**에 비유
* 강의 목표: 인간이 **무의식적으로 수행하는 언어 학습의 기적**을 공학적으로 해석

---

## 🧬 언어의 기적: 복수형 규칙 학습 사례

### 🗣️ 영어 복수형 예

* `cat → cats (s)`
* `dog → dogs (z)`
* **Krishna (비원어민)**도 정확히 구분하여 발음함 → 무의식적 규칙 학습
* 음성 특징:

  * `cats`: 무성자음(s), vocal cord 진동 없음
  * `dogs`: 유성자음(z), vocal cord 진동 있음

---

## 🎧 음성 인식과 특징 추출

### 🎼 구별적 특징(distinctive features)

* 음소(phoneme)를 14개의 이진 특성으로 표현
* 예: \[Voiced], \[Syllabic], \[Continuent], \[Strident] 등
* 예: "apples" 발화 시 각 음소의 특징 매트릭스로 표현
* **맥거크 효과(McGurk Effect)**: 시각 정보가 청각에 영향 줌 → **다중 모달 통합 처리**

---

## 🏗️ Sussman-Yip 기계: 제약 기반 언어 생성 시스템

### 🧠 구성 요소

* 시각 인식 모듈 → 단어 인식 → **개념 레지스터(nouns, plurals 등)**
* 단어-음소 매핑 사전
* **버퍼(Buffer)**: 생성될 음소 순서 저장
* **제약(Constraint)**: 다방향 정보 흐름 → **propagator**

### 🔁 예시: 사과 두 개 → “apples” 생성 과정

1. 시각 → 복수 개념 활성화
2. `apple` 단어 매칭 → buffer에 a-p-l 입력
3. 제약 `plural + voiced → z` 활성화 조건 점검
4. buffer 이동하며 `l`이 `voiced`임을 인식
5. `z` 추가됨 → `a-p-l-z` → **복수형 생성 완료**
6. 모든 제약은 **역방향 추론도 가능** (예: “apples” 듣고 장면 상상)

---

## 🧪 학습 메커니즘: 제약 학습 알고리즘

### 🎓 문제 정의

* 목표: `cats`와 `dogs` 같은 단어에서 **어떤 음소 특징이 복수형 결정하는지 학습**

### 🧩 실험 예시

* cats = `k-a-t-s`, dogs = `d-o-g-z`
* 비교 대상: \[Voiced], \[Continuent], \[Strident], \[Syllabic] 등

### 🔎 탐색 전략

1. **Seed 선택**: 양성 예제(cat)로 시작
2. **일반화(Generalize)**: 중요하지 않은 특징은 `*` 처리
3. 음소 매트릭스를 확장 → 음소 특징을 덜 보되 예측 정확도 유지
4. **부정 예제를 포용할 경우 일반화 중단**
5. **우선순위**: 인접 음소부터 일반화 시작 (가까울수록 영향력 큼)

### 🧪 결과

* 무성, 비-strident → `s` (예: cats)
* 유성 → `z` (예: dogs)
* strident → `əz` (예: beaches)

---

## 🧠 Sparse Space 가설

### 📐 고차원 공간의 일반화 가능성

* 14차원 구별적 특징 → 총 $$2^{14} = 16,384$$ 조합 가능
* 실제 사용 음소는 \~40개
* 🎯 고차원 공간일수록 **단순한 구분 평면(hyperplane)**으로 분류 쉬움

### 🔍 이유

1. **학습 가능성(learnability)**: 고차원 희소 공간이 학습 용이성 제공
2. **중앙극한정리(CLT)** → 무작위 분포 시 음소 간 간격 균등해짐 → 혼동 방지

### 📊 실험적 검증

* 음소 간 구별 특성 1개 차이로 연결된 네트워크 시각화
* 결과: 자음 간 간격 큼 → **구분 쉬움**, 모음은 가까움 → **구분 어려움**

---

## 🧱 Marr의 AI 접근 5단계 (Marr's Catechism)

1. **문제 정의**
2. **표현 정의** (구별적 특징 등)
3. **처리 방식(approach)** 도출
4. **메커니즘/알고리즘** 설계
5. **실험 및 검증**

> 핵심: 기계학습은 메커니즘 집착이 아닌, 문제 중심 접근으로 구성되어야 함

---

## ✅ 정리

* Sussman-Yip 시스템은 **음소 규칙을 학습**하기 위한 제약 기반 시스템
* 복수형 결정은 주변 음소의 특징에 의해 결정됨
* 제약은 방향 없는 정보 전파 가능 → 표현, 생성, 추론 모두 가능
* Marr의 접근은 **AI 시스템 설계에 본질적 지침 제공**
* 💡 교훈:

  * **좋은 표현(Representation)**은 제약을 드러낸다
  * 제약 기반 학습은 추상 규칙 학습에 효과적이다
