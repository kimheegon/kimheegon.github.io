---

title: "[MIT6.034] 16.원샷 학습과 설명 기반 학습(EBL), 학습 설계 전략"
date: 2025-06-05 06:00:00 +0900
categories: [AI, AI-Lecture]
tags: [MIT-6.034, One-Shot Learning, Explanation-Based Learning, Felicity Condition, Self-Talk]
math: true
---

**MIT AI 강의 16 - 원샷 학습, 설명 기반 학습, 학습 설계와 지능 향상 전략**

---

## **핵심 목표**

* 학습에서 **단일 예시(one-shot)**를 통해 구체적 지식 추출 가능
* **자기 설명(self-explanation)**이 학습과 문제 해결 능력을 크게 향상시킴
* **교사-학생 모델(felicity condition)**을 기반으로 효과적인 학습 구조 제안

---


## **원샷 학습: 아치 학습 사례**

> **원샷 학습이란?**
> - 적은 수의 예시만으로도 일반적인 개념을 학습하는 능력
> - 인간은 몇 번의 경험만으로 일반화를 잘 수행함
> - 컴퓨터는 수천 개의 예시가 필요하지만, 이 방법은 이를 극복하는 접근 중 하나  

> **아치 학습**
> 정답 예시 (arch)
> - 두 기둥 위에 블록이 얹혀 있는 구조
> - → 이걸 보고 "이게 아치야"라고 배움
> 
> near miss 예시 (틀린 아치)
> - 블록이 기둥과 맞닿아 있어서 위에 떠있지 않음
> - → 왜 틀렸을까? → "기둥이 블록을 지지해야만 하네"
> - → "기둥과 블록이 붙어있으면 안 된다"는 제약 조건도 배움
> 
> 다른 예시들 추가됨
> - 아치 색이 바뀌어도 OK → 색은 중요하지 않음
> - 꼭대기 블록 모양이 달라도 OK → 모양은 일반화 가능


### **핵심 원리**

* 초기 예시(ex: arch) → 이후 유사하지만 조건이 다른 near-miss 제시
* 구조적 차이점 → **제약 조건(constraints)** 추출
* 하나의 예시와 하나의 near-miss로도 **명확한 지식 추출 가능**

### **단계별 학습**

1. 초기 모델에서 지원(support) 관계 중요성 발견 → `must-support`
2. 사이드 간 접촉 발견 → `must-not-touch`
3. 색상 변화(red) 허용 → `extend-set`
4. 색상 blue 등장 → `drop-link (color irrelevant)`
5. top이 wedge 형태 → 범주 트리(climb-tree)로 일반화

### **Heuristic 명칭 정리 (by Malkovsky)**

* `Require Link`: 필수 관계
* `Forbid Link`: 금지 관계
* `Extend Set`: 허용되는 값 범위 확장
* `Drop Link`: 속성 무관화
* `Climb Tree`: 상위 범주 일반화

---

## **Train Problem: 집합 분류 기반 학습**

## **문제 정의**

* 위/아래 두 줄의 기차 예시가 주어짐  
  → 각각의 기차는 다양한 속성(차량 개수, 색상, 모양 등)을 가짐  
* 목표: 위 열 기차들의 공통된 규칙을 찾아 **분류 기준 학습**

> 예:  
> 위 열 기차들에는 모두 **짧고 닫힌 차량**이 있음  
> 아래 열 기차들에는 해당 특성이 없음

---

## **학습 방식**

### 1. **Seed 선택**

* 위쪽 열에서 하나의 기차를 골라 학습 시작점으로 삼음

### 2. **일반화 (Generalization)**

* Seed 기차가 가진 속성을 점차 확장하여 더 많은 `positives`를 커버하도록 함  
  → 예: "짧은 차량" → "짧고 닫힌 차량" 등

### 3. **전문화 (Specialization)**

* 동시에 `negatives`에 해당하지 않도록 제약을 추가함  
  → 예: "파란색 차량은 제외", "기차 길이는 3 이하" 등

---

## **탐색 문제로서의 구조**

* 어떤 조건을 붙이거나 제거하거나 조합하는 방식은 **탐색 트리**를 이룸  
* 가능한 조합이 매우 많아 **탐색 공간이 큼**

---

## **Beam Search 적용**

* 해결책: **Beam Search**
  * 탐색 과정에서 가지 수를 제한하는 전략
  * 매 단계마다 **상위 k개의 후보 규칙**만 유지하며 확장
  * → 계산량을 줄이고 중요한 조건 중심으로 학습 가능

---

## **일반화 vs 전문화**

| **Near Miss 기반 학습**          | **예시 기반 학습**                      |
| -------------------------------- | --------------------------------------- |
| ➖ 제약 추가 → 전문화             | ➕ 조건 완화 → 일반화                    |
| `must-support`, `must-not-touch` | `extend-set`, `drop-link`, `climb-tree` |

  > 결론: **Near-miss → 전문화 / Example → 일반화**

---

## **Felicity Condition: 교사-학생 학습 설계 모델**

### **목표**

* 학생의 초기 지식 상태 → 새로운 지식 획득으로 변환
* **교사-학생 간 상호 이해 필요**

### **교사의 조건**

1. **학생의 wavefront 위치 파악** (지식 네트워크 상 위치)
2. **학생의 처리 능력 이해**

   * 예: 컴퓨터(대량 학습 가능) vs 3학년(단계적 제시 필요)
3. **타이밍 구분**

   * m1: 과거 실수 → 상기
   * m2: 미래 지식 → 보류
   * m3: 현재 학습 타이밍 → 설명 시작

### **학생의 조건**

1. **교사에 대한 신뢰**
2. **교사의 스타일 파악 및 기대 조절**

---

## **자기 설명(Self-Explanation)과 학습 효과**

### **실험 결과 (Michelene Chi)**

* 8명 학생, 물리 문제 학습 및 시험
* 상위 4명 vs 하위 4명:

  * 자기 설명 횟수: **35회 vs 10회**
  * 시험 성적: **2배 차이**
* 유형:

  * **메타 인지적**: “모르겠다”, “막혔다”
  * **지식 기반**: “F=ma 써보자”, “힘 다이어그램 그리자”

> **결론: 자기 설명 많을수록 학습 성과 우수**

---

## **아이디어를 포장하는 5S 전략**

| 항목         | 설명                                             |
| ------------ | ------------------------------------------------ |
| **Symbol**   | 시각적 상징: 예) 아치 그림                       |
| **Slogan**   | 언어적 요약: “near miss 기반 학습”               |
| **Surprise** | 예기치 않은 결과: “컴퓨터도 원샷 학습 가능”      |
| **Salient**  | 두드러진 요소: 핵심 개념 하나가 튀어나옴         |
| **Story**    | 스토리 구조: 사례 중심 설명, Julia Child 예시 등 |

---

## **정리**

* 사람처럼 **소수의 예시에서 일반화/전문화** 가능한 시스템은 설명 기반 학습의 정수
* 학습을 위한 핵심 전략:

  1. 예시 vs near miss를 구분하여 처리
  2. 각 상황에 적절한 히리스틱 활용
  3. 교사-학생 간 **상호 이해 기반 설계**
  4. 학습자는 자기 설명을 통한 내적 반추 수행
* 💡 핵심: **좋은 학습은 설계로부터 출발하며, 자기 설명이 학습을 완성한다**
